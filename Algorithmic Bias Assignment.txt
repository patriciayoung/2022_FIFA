
* What did the algorithm do?

It reflected real world bias by qualifying patients based on not only their medical expenses, but their race as well.


* What information did the algorithm use to make its predictions?

it used medical costs, which is consdiered a common benchmark to summarize health care needs, but it also took chronic illnesses, race, and income into account.


* What information did the researchers use to determine that the algorithm was biased?

The researchers found that black patients tended to receivver lower risk scores, among patients classified as very high risk, black individuals tunred out to have 26.3% more chronic illnesses than white ones, despite sharing similar risk score.

3

* What was the impact of the algorithmic bias?

It took a bigger toll on black individuals financially, because even though they were marked with the same risk score, they did not have the same level of need, casuing black individuals to pay more for interventions. It also impacted black individuals health in general, as not receiving the adequate care to begin with, would cause them to have less trust in their doctors.

* What were the primary causes of the bias?

As the article addresses that "Algorithms still reflect the real world" and they can perpetuate existing inequality. The article also mentions that "race and income are correlated" which would make black patients less likely to use medical services even when they are crucial for their future health. Lastly, a lack of diversity in the data and the amount of data itself causes a bias since nearly 88% of the individuals were white, while only 12% were as black.


* How might you address the issues that the researchers found?

Having the AI focus on only medical history and costs would be ideal, perhaps even income, but it should not facotr race in their algortihm. If doctors believe that race might be important in addressing ones possible medical needs, we would suggest adding more data, to try to add more diversity and hopefully fix the current bias.